{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отчет\n",
    "\n",
    "'X', 'Y', 'Month', 'Year',\n",
    "n_estimators=30, max_depth=10:\n",
    "2.45973964768\n",
    "\n",
    "'X', 'Y', 'Month', 'Year', 'Hour'\n",
    "n_estimators=30, max_depth=10:\n",
    "2.45612199334\n",
    "\n",
    "'X', 'Y', 'Month', 'Year', 'Hour'\n",
    "n_estimators=70, max_depth=15:\n",
    "2.3770777449\n",
    "\n",
    "Внезапно, если выкинуть месяц - результат улучшается.\n",
    "'X', 'Y', 'Month', 'Year', 'Hour'\n",
    "n_estimators=70, max_depth=15:\n",
    "2.37622850483\n",
    "\n",
    "Если выкинуть год но оставить месяц - результат ухудшается.\n",
    "'X', 'Y', 'Month', 'Year', 'Hour'\n",
    "n_estimators=70, max_depth=15:\n",
    "2.39490375842\n",
    "\n",
    "Если использовать только координаты и час - результат так же ухудшается.\n",
    "'X', 'Y', 'Hour'\n",
    "n_estimators=70, max_depth=15:\n",
    "2.41821809425\n",
    "\n",
    "Добавление фичи Minutes позволило улучшить результат\n",
    "'X', 'Y', 'Year', 'Hour', 'Minutes'\n",
    "n_estimators=70, max_depth=15\n",
    "2.36959679856\n",
    "\n",
    "Выкидываем часы и получаем очередно улучшение модели\n",
    "'X', 'Y', 'Year', 'Minutes'\n",
    "n_estimators=70, max_depth=15\n",
    "2.36056042616\n",
    "\n",
    "######## Новый день, новые тесты\n",
    "- Увеличиваем кол-во деревье до 80, немного улучшаем показатели модели\n",
    "'X', 'Y', 'Year', 'Minutes'\n",
    "n_estimators=300, max_depth=15\n",
    "2.3467849756212078\n",
    "\n",
    "Подгоняем max_debth и еще немного улучшаем модель\n",
    "'X', 'Y', 'Year', 'Minutes'\n",
    "n_estimators=200, max_depth=17\n",
    "2.3434 - *Best*\n",
    "\n",
    "n_estimators=300, max_depth=17 почитать не получилось из-за memory error.\n",
    "\n",
    "На практике результат на Kaggle для модели с 200 деревьями и глубиной 17 оказался хуже чем у прошлой модели.\n",
    "\n",
    "**На данный момент наилучшие показатели дает модель:**\n",
    "'X', 'Y', 'Year', 'Minutes'\n",
    "n_estimators=70, max_depth=15\n",
    "2.36056042616\n",
    "\n",
    "\n",
    "\n",
    "#########\n",
    "Нормализация по координатам ухудшает модель\n",
    "2.361\n",
    "\n",
    "(используются 'X', 'Y', 'Month', 'Year', 'Hour')\n",
    "При обучении max_depath=10, при количестве деревьев до 70 качество log_loss улучгается (вплоть до 2.4517821589206741), после 70 деревьев показатели ухудшаются.\n",
    "\n",
    "При обучении n_estimators=30, качество log_loss улучшается до 15, деревьев,  (2.4033074972863218). После 15 деревьев показатели резко ухудшаются.\n",
    "\n",
    "Совмещая два вышеуказанных показателя (n_estimators=70, max_depth=15) удалось получить: 2.3770777449\n",
    "\n",
    "Введение переменной Night ухудшает модель (2.39742976255)\n",
    "\n",
    "Рассчет на 300 деревьях ухудшает результат (2.38157899729)\n",
    "\n",
    "Попытка построить модель отдельно для Night и отдельно для Day ухудшает модель (2.42175093186 для дня, 2.5 для ночи. Под ночью понималось время > 19 и < 7)\n",
    "\n",
    "Использование criterion=\"entropy\" вместо \"gini\" ухудшает модель (2.39547290223 при 70 деревьях)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# San Francisco Crime Data Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Base\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Tools\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "# Metrics\n",
    "from sklearn.metrics import log_loss\n",
    "# Classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rs = 42 # random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/sf_crime/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_data(data):\n",
    "    data['Dates'] = pd.to_datetime(data['Dates'])\n",
    "    data['Month'] = data['Dates'].apply(lambda i: i.month)\n",
    "    data['Year'] = data['Dates'].apply(lambda i: i.year)\n",
    "    data['Hour'] = data['Dates'].apply(lambda i: i.hour)\n",
    "    data['Minutes'] = data['Dates'].apply(lambda i: \\\n",
    "                                          i.hour*60 + i.minute)\n",
    "#     data['Night'] = (data['Hour'] > 19) | (data['Hour'] < 7)\n",
    "\n",
    "    categorycal_cols = ['Category', 'Descript', 'DayOfWeek', 'PdDistrict',\n",
    "                        'Resolution', 'Address', 'Night']\n",
    "    for category in categorycal_cols:\n",
    "        if category in data:\n",
    "            data[category] = data[category].astype('category')\n",
    "    \n",
    "    return data\n",
    "\n",
    "def split_data(X, y):\n",
    "    return train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = transform_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Category</th>\n",
       "      <th>Descript</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>WARRANTS</td>\n",
       "      <td>WARRANT ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>23</td>\n",
       "      <td>1433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>23</td>\n",
       "      <td>1433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Dates        Category                  Descript  DayOfWeek  \\\n",
       "0 2015-05-13 23:53:00        WARRANTS            WARRANT ARREST  Wednesday   \n",
       "1 2015-05-13 23:53:00  OTHER OFFENSES  TRAFFIC VIOLATION ARREST  Wednesday   \n",
       "\n",
       "  PdDistrict      Resolution             Address           X          Y  \\\n",
       "0   NORTHERN  ARREST, BOOKED  OAK ST / LAGUNA ST -122.425892  37.774599   \n",
       "1   NORTHERN  ARREST, BOOKED  OAK ST / LAGUNA ST -122.425892  37.774599   \n",
       "\n",
       "   Month  Year  Hour  Minutes  \n",
       "0      5  2015    23     1433  \n",
       "1      5  2015    23     1433  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of  70 | elapsed:    1.9s remaining:  2.3min\n",
      "[Parallel(n_jobs=4)]: Done  70 out of  70 | elapsed:   32.7s finished\n",
      "[Parallel(n_jobs=4)]: Done   1 out of  70 | elapsed:    0.1s remaining:   10.7s\n",
      "[Parallel(n_jobs=4)]: Done  70 out of  70 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.36056042616\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "y = data['Category']#.cat.codes\n",
    "X = data[['X', 'Y', 'Year', 'Minutes']]\n",
    "X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=70, max_depth=15, n_jobs=4,\n",
    "                             random_state=rs, verbose=True)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "proba = clf.predict_proba(X_test)\n",
    "loss = log_loss(y_test, proba)\n",
    "\n",
    "print(loss)\n",
    "\n",
    "print('Done')\n",
    "\n",
    "# 2.36056042616"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of 300 | elapsed:    0.1s remaining:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed:   17.0s finished\n",
      "[Parallel(n_jobs=4)]: Done   1 out of 300 | elapsed:    0.0s remaining:   12.5s\n",
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 2.3854960849457894)\n"
     ]
    }
   ],
   "source": [
    "# Попробуем отдельно попредсказывать для лета и зимы\n",
    "summer_data = data[(data['Month']==6) |\n",
    "                   (data['Month']==7) |\n",
    "                   (data['Month']==8)]\n",
    "y = summer_data['Category']\n",
    "X = summer_data[['X', 'Y', 'Year', 'Minutes']]\n",
    "X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=300, max_depth=14, n_jobs=4,\n",
    "                             random_state=rs, verbose=True)\n",
    "clf.fit(X_train, y_train)\n",
    "proba = clf.predict_proba(X_test)\n",
    "loss = log_loss(y_test, proba)\n",
    "print(d, loss)\n",
    "\n",
    "# 14 деревьев - оптимально\n",
    "# Для лета (month=6,7,8)     \n",
    "# n=300, max_debth=14\n",
    "# 300, 2.3849\n",
    "\n",
    "# Для зимы (month=12,1,2)\n",
    "# n=300, max_debth=14, 2.396"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of  30 | elapsed:    0.6s remaining:   19.3s\n",
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:    5.1s finished\n",
      "[Parallel(n_jobs=4)]: Done   1 out of  30 | elapsed:    0.0s remaining:    2.7s\n",
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.42175093186\n"
     ]
    }
   ],
   "source": [
    "night_data = data[data['Night'] == 0]\n",
    "y = night_data['Category']\n",
    "X = night_data[['X', 'Y', 'Month', 'Year', 'Hour']]\n",
    "X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=30, max_depth=10, n_jobs=4,\n",
    "                             random_state=rs, verbose=True)\n",
    "clf.fit(X_train, y_train)\n",
    "proba = clf.predict_proba(X_test)\n",
    "loss = log_loss(y_test, proba)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of 200 | elapsed:    2.2s remaining:  7.6min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=17, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=4,\n",
       "            oob_score=False, random_state=42, verbose=True,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Submit\n",
    "X = data[['X', 'Y', 'Year', 'Hour']]\n",
    "y = data['Category']\n",
    "clf = RandomForestClassifier(n_estimators=70, max_depth=15, n_jobs=4,\n",
    "                             random_state=rs, verbose=True)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/sf_crime/test.csv')\n",
    "nrows = df.shape[0]\n",
    "del(df)\n",
    "\n",
    "\n",
    "def to_ans_format(proba, start_id):\n",
    "    ans = []\n",
    "    for id in xrange(len(proba)):\n",
    "        row = list(proba[id])\n",
    "        row = [start_id + id] + row\n",
    "        ans.append(row)\n",
    "    ans = pd.DataFrame(ans)\n",
    "    ans.columns = ['Id'] + list(clf.classes_)\n",
    "    return ans\n",
    "\n",
    "\n",
    "def submit_partial(clf, nrows, path_to_data, path_to_ans):\n",
    "    chunk_size = 10\n",
    "    done = 0\n",
    "    first_iter = True\n",
    "    open(path_to_ans, 'w+').close()\n",
    "    while done < nrows:\n",
    "        print('Done: {0}/{1}'.format(done, nrows))\n",
    "        test_data = pd.read_csv('./data/sf_crime/test.csv',\n",
    "                                skiprows=xrange(1, done+1), # 1 - to read header\n",
    "                                nrows=chunk_size)\n",
    "        start_id = test_data['Id'][0]\n",
    "        done += chunk_size\n",
    "        print('start id: ', start_id)\n",
    "        test_data = transform_data(test_data)\n",
    "        test_data = test_data[['X', 'Y', 'Year', 'Hour']]\n",
    "        proba = clf.predict_proba(test_data)\n",
    "        ans = to_ans_format(proba, start_id)\n",
    "        ans.to_csv('./data/sf_crime/res.csv', mode='a', index=False,\n",
    "                  header=first_iter)\n",
    "        first_iter = False\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 0/884262\n",
      "('start id: ', 0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of 200 | elapsed:    0.0s remaining:   12.4s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done: 100000/884262\n",
      "('start id: ', 100000)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of 200 | elapsed:    1.6s remaining:  5.6min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:   12.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done: 200000/884262\n",
      "('start id: ', 200000)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of 200 | elapsed:    1.2s remaining:  4.5min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:   15.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done: 300000/884262\n",
      "('start id: ', 300000)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of 200 | elapsed:    2.1s remaining:  7.4min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:   22.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done: 400000/884262\n",
      "('start id: ', 400000)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of 200 | elapsed:    1.0s remaining:  3.6min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:   23.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done: 500000/884262\n",
      "('start id: ', 500000)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of 200 | elapsed:    1.4s remaining:  4.9min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:   30.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done: 600000/884262\n",
      "('start id: ', 600000)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of 200 | elapsed:    1.9s remaining:  6.7min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:   53.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done: 700000/884262\n",
      "('start id: ', 700000)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of 200 | elapsed:    0.9s remaining:  3.4min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done: 800000/884262\n",
      "('start id: ', 800000)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of 200 | elapsed:    0.7s remaining:  2.5min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:   49.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "submit_partial(clf, nrows, './data/sf_crime/test.csv',\n",
    "               './data/sf_crime/ans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('./data/sf_crime/test.csv', skiprows=xrange(1, 10), nrows=100000,)\n",
    "test_data = transform_data(test_data)\n",
    "test_data = test_data[['X', 'Y', 'Year', 'Hour']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of 200 | elapsed:    0.0s remaining:   10.4s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    2.7s finished\n"
     ]
    }
   ],
   "source": [
    "proba = clf.predict_proba(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id     ARSON   ASSAULT  BAD CHECKS   BRIBERY  BURGLARY  DISORDERLY CONDUCT  \\\n",
      "0   0  0.002240  0.118271    0.000033  0.000446  0.021406            0.001727   \n",
      "1   1  0.001321  0.094248    0.000057  0.001204  0.012745            0.002711   \n",
      "\n",
      "   DRIVING UNDER THE INFLUENCE  DRUG/NARCOTIC  DRUNKENNESS     ...       \\\n",
      "0                      0.00566       0.019943     0.000659     ...        \n",
      "1                      0.00298       0.042819     0.003727     ...        \n",
      "\n",
      "   SEX OFFENSES NON FORCIBLE  STOLEN PROPERTY   SUICIDE  SUSPICIOUS OCC  \\\n",
      "0                   0.000153         0.004651  0.001098        0.044409   \n",
      "1                   0.000236         0.002473  0.001038        0.036614   \n",
      "\n",
      "       TREA  TRESPASS  VANDALISM  VEHICLE THEFT  WARRANTS  WEAPON LAWS  \n",
      "0  0.000000  0.004337   0.073504       0.163536  0.023281     0.021432  \n",
      "1  0.000118  0.002719   0.032138       0.086312  0.072499     0.027582  \n",
      "\n",
      "[2 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "ans = []\n",
    "\n",
    "for id in xrange(len(proba)):\n",
    "    row = list(proba[id])\n",
    "    row = [id] + row\n",
    "    ans.append(row)\n",
    "\n",
    "ans = pd.DataFrame(ans)\n",
    "ans.columns = ['Id'] + list(clf.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ans.to_csv('./data/sf_crime/res.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "y = data['Category']#.cat.codes\n",
    "X = data[['X', 'Y']] # 'Year',  'Minutes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\soft\\dev\\anaconda\\lib\\site-packages\\IPython\\kernel\\__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "D:\\soft\\dev\\anaconda\\lib\\site-packages\\IPython\\kernel\\__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# X['Year'] = scale(X['Year'].astype('float64'))\n",
    "# X['Minutes'] = scale(X['Minutes'].astype('float64'))\n",
    "X['X'] = scale(X['X'])\n",
    "X['Y'] = scale(X['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusters = KMeans(n_clusters=5, random_state=rs).fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 4, 4, 4])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl = map(lambda i: i == 0, clusters)\n",
    "\n",
    "y = data[cl]['Category']\n",
    "X = data[cl][['X', 'Y', 'Year', 'Minutes']]\n",
    "\n",
    "non_trea_ind = (y != 'TREA')\n",
    "y = y[non_trea_ind]\n",
    "X = X[non_trea_ind]\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of 100 | elapsed:    0.4s remaining:   52.5s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   13.4s finished\n",
      "[Parallel(n_jobs=4)]: Done   1 out of 100 | elapsed:    0.0s remaining:    8.4s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3351149024\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=14, n_jobs=4,\n",
    "                             random_state=rs, verbose=True)\n",
    "clf.fit(X_train, y_train)\n",
    "proba = clf.predict_proba(X_test)\n",
    "loss = log_loss(y_test, proba)\n",
    "\n",
    "print(loss)\n",
    "\n",
    "# 2.350\n",
    "\n",
    "# print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С кластеризацией добиться нормальных результатов пока не получилось.\n",
    "Для одних кластеров результат лучше чем в среднем по больнице, для других хуже.\n",
    "Основная проблема - из за выпадающих категорий может не работать `log_loss`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
