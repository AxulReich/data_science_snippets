{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отчет\n",
    "\n",
    "'X', 'Y', 'Month', 'Year',\n",
    "n_estimators=30, max_depth=10:\n",
    "2.45973964768\n",
    "\n",
    "'X', 'Y', 'Month', 'Year', 'Hour'\n",
    "n_estimators=30, max_depth=10:\n",
    "2.45612199334\n",
    "\n",
    "'X', 'Y', 'Month', 'Year', 'Hour'\n",
    "n_estimators=70, max_depth=15:\n",
    "2.3770777449\n",
    "\n",
    "Внезапно, если выкинуть месяц - результат улучшается.\n",
    "'X', 'Y', 'Month', 'Year', 'Hour'\n",
    "n_estimators=70, max_depth=15:\n",
    "2.37622850483\n",
    "\n",
    "Если выкинуть год но оставить месяц - результат ухудшается.\n",
    "'X', 'Y', 'Month', 'Year', 'Hour'\n",
    "n_estimators=70, max_depth=15:\n",
    "2.39490375842\n",
    "\n",
    "Если использовать только координаты и час - результат так же ухудшается.\n",
    "'X', 'Y', 'Hour'\n",
    "n_estimators=70, max_depth=15:\n",
    "2.41821809425\n",
    "\n",
    "Добавление фичи Minutes позволило улучшить результат\n",
    "'X', 'Y', 'Year', 'Hour', 'Minutes'\n",
    "n_estimators=70, max_depth=15\n",
    "2.36959679856\n",
    "\n",
    "Выкидываем часы и получаем очередно улучшение модели\n",
    "'X', 'Y', 'Year', 'Minutes'\n",
    "n_estimators=70, max_depth=15\n",
    "2.36056042616\n",
    "\n",
    "######## Новый день, новые тесты\n",
    "- Увеличиваем кол-во деревье до 80, немного улучшаем показатели модели\n",
    "'X', 'Y', 'Year', 'Minutes'\n",
    "n_estimators=300, max_depth=15\n",
    "2.3467849756212078\n",
    "\n",
    "Подгоняем max_debth и еще немного улучшаем модель\n",
    "'X', 'Y', 'Year', 'Minutes'\n",
    "n_estimators=200, max_depth=17\n",
    "2.3434 *(отличный тестовый показатель, но сабмит данной модели на Kaggle дает результат хуже чем у модели 70-15)*\n",
    "\n",
    "n_estimators=300, max_depth=17 почитать не получилось из-за memory error.\n",
    "\n",
    "На практике результат на Kaggle для модели с 200 деревьями и глубиной 17 оказался хуже чем у прошлой модели.\n",
    "\n",
    "**На данный момент наилучшие показатели дает модель:**\n",
    "'X', 'Y', 'Year', 'Minutes'\n",
    "n_estimators=70, max_depth=15\n",
    "2.36056042616\n",
    "\n",
    "######### Третий заход\n",
    "\n",
    "Добавление информации о Пятнице и подкручивание парамтеров помогло улучшить параметры дерева\n",
    "\n",
    "'X', 'Y', 'Year', 'Minutes', 'isFriday'\n",
    "n_estimators=200, max_depth=16\n",
    "2.34931596509 - *Best*\n",
    "\n",
    "Похоже стоит построить bag of words из дней недели.\n",
    "\n",
    "#########\n",
    "Нормализация по координатам ухудшает модель\n",
    "2.361\n",
    "\n",
    "(используются 'X', 'Y', 'Month', 'Year', 'Hour')\n",
    "При обучении max_depath=10, при количестве деревьев до 70 качество log_loss улучгается (вплоть до 2.4517821589206741), после 70 деревьев показатели ухудшаются.\n",
    "\n",
    "При обучении n_estimators=30, качество log_loss улучшается до 15, деревьев,  (2.4033074972863218). После 15 деревьев показатели резко ухудшаются.\n",
    "\n",
    "Совмещая два вышеуказанных показателя (n_estimators=70, max_depth=15) удалось получить: 2.3770777449\n",
    "\n",
    "Введение переменной Night ухудшает модель (2.39742976255)\n",
    "\n",
    "Рассчет на 300 деревьях ухудшает результат (2.38157899729)\n",
    "\n",
    "Попытка построить модель отдельно для Night и отдельно для Day ухудшает модель (2.42175093186 для дня, 2.5 для ночи. Под ночью понималось время > 19 и < 7)\n",
    "\n",
    "Использование criterion=\"entropy\" вместо \"gini\" ухудшает модель (2.39547290223 при 70 деревьях)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# San Francisco Crime Data Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Base\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Tools\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "# Metrics\n",
    "from sklearn.metrics import log_loss\n",
    "# Classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rs = 42 # random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/sf_crime/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_data(data):\n",
    "    data['Dates'] = pd.to_datetime(data['Dates'])\n",
    "    data['Month'] = data['Dates'].apply(lambda i: i.month)\n",
    "    data['Year'] = data['Dates'].apply(lambda i: i.year)\n",
    "    data['Hour'] = data['Dates'].apply(lambda i: i.hour)\n",
    "    data['Minutes'] = data['Dates'].apply(lambda i: \\\n",
    "                                          i.hour*60 + i.minute)\n",
    "#     data['Night'] = (data['Hour'] > 19) | (data['Hour'] < 7)\n",
    "    days_of_week = ['Sunday', 'Saturday', 'Friday', 'Thursday', 'Wednesday', 'Tuesday', 'Monday']\n",
    "    for day in days_of_week:\n",
    "        data[day] = data['DayOfWeek'].apply(lambda current_day: current_day == day)\n",
    "    \n",
    "    categorycal_cols = ['Category', 'Descript', 'DayOfWeek', 'PdDistrict',\n",
    "                        'Resolution', 'Address', 'Night']\n",
    "    for category in categorycal_cols:\n",
    "        if category in data:\n",
    "            data[category] = data[category].astype('category')\n",
    "    \n",
    "    return data\n",
    "\n",
    "def split_data(X, y):\n",
    "    return train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "def to_ans_format(proba, start_id):\n",
    "    ans = []\n",
    "    for id in xrange(len(proba)):\n",
    "        row = list(proba[id])\n",
    "        row = [start_id + id] + row\n",
    "        ans.append(row)\n",
    "    ans = pd.DataFrame(ans)\n",
    "    ans.columns = ['Id'] + list(clf.classes_)\n",
    "    return ans\n",
    "\n",
    "\n",
    "def submit_partial(clf, nrows, path_to_data, path_to_ans):\n",
    "    chunk_size = 100000\n",
    "    done = 0\n",
    "    first_iter = True\n",
    "    open(path_to_ans, 'w+').close()\n",
    "    while done < nrows:\n",
    "        print('Done: {0}/{1}'.format(done, nrows))\n",
    "        test_data = pd.read_csv('./data/sf_crime/test.csv',\n",
    "                                skiprows=xrange(1, done+1), # 1 - to read header\n",
    "                                nrows=chunk_size)\n",
    "        start_id = test_data['Id'][0]\n",
    "        done += chunk_size\n",
    "        print('start id: ', start_id)\n",
    "        test_data = transform_data(test_data)\n",
    "        test_data = test_data[['X', 'Y', 'Year', 'Hour', 'Friday']]\n",
    "        proba = clf.predict_proba(test_data)\n",
    "        ans = to_ans_format(proba, start_id)\n",
    "        ans.to_csv('./data/sf_crime/res.csv', mode='a', index=False,\n",
    "                  header=first_iter)\n",
    "        first_iter = False\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = transform_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Category</th>\n",
       "      <th>Descript</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minutes</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Thursday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>WARRANTS</td>\n",
       "      <td>WARRANT ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>23</td>\n",
       "      <td>1433</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>23</td>\n",
       "      <td>1433</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Dates        Category                  Descript  DayOfWeek  \\\n",
       "0 2015-05-13 23:53:00        WARRANTS            WARRANT ARREST  Wednesday   \n",
       "1 2015-05-13 23:53:00  OTHER OFFENSES  TRAFFIC VIOLATION ARREST  Wednesday   \n",
       "\n",
       "  PdDistrict      Resolution             Address           X          Y  \\\n",
       "0   NORTHERN  ARREST, BOOKED  OAK ST / LAGUNA ST -122.425892  37.774599   \n",
       "1   NORTHERN  ARREST, BOOKED  OAK ST / LAGUNA ST -122.425892  37.774599   \n",
       "\n",
       "   Month  Year  Hour  Minutes Wednesday Tuesday Monday Sunday Saturday Friday  \\\n",
       "0      5  2015    23     1433      True   False  False  False    False  False   \n",
       "1      5  2015    23     1433      True   False  False  False    False  False   \n",
       "\n",
       "  Thursday  \n",
       "0    False  \n",
       "1    False  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of 150 | elapsed:    1.8s remaining:  4.8min\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=4)]: Done   1 out of 150 | elapsed:    0.1s remaining:   30.4s\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    9.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.36423512396\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "days_of_week = list(data['DayOfWeek'].unique())\n",
    "y = data['Category']#.cat.codes\n",
    "X = data[['X', 'Y', 'Year', 'Minutes'] + ['Friday']]\n",
    "X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=70, max_depth=15, n_jobs=4,\n",
    "                             random_state=rs, verbose=True)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "proba = clf.predict_proba(X_test)\n",
    "loss = log_loss(y_test, proba)\n",
    "\n",
    "print(loss)\n",
    "\n",
    "print('Done')\n",
    "\n",
    "# 2.36056042616\n",
    "# 2.34931596509 (\"Friday\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of 100 | elapsed:    1.8s remaining:  3.1min\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   48.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=16, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=4,\n",
       "            oob_score=False, random_state=42, verbose=True,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Submit\n",
    "X = data[['X', 'Y', 'Year', 'Hour', 'Friday']]\n",
    "y = data['Category']\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=16, n_jobs=4,\n",
    "                             random_state=rs, verbose=True)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/sf_crime/test.csv')\n",
    "nrows = df.shape[0]\n",
    "del(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 0/884262\n",
      "('start id: ', 0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of 100 | elapsed:    0.0s remaining:    6.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done: 100000/884262\n",
      "('start id: ', 100000)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of 100 | elapsed:    0.0s remaining:    6.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done: 200000/884262\n",
      "('start id: ', 200000)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of 100 | elapsed:    0.0s remaining:    7.6s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done: 300000/884262\n",
      "('start id: ', 300000)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of 100 | elapsed:    0.0s remaining:    6.1s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done: 400000/884262\n",
      "('start id: ', 400000)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of 100 | elapsed:    0.0s remaining:    6.7s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done: 500000/884262\n",
      "('start id: ', 500000)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of 100 | elapsed:    0.0s remaining:    6.5s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done: 600000/884262\n",
      "('start id: ', 600000)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of 100 | elapsed:    0.0s remaining:    6.1s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done: 700000/884262\n",
      "('start id: ', 700000)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of 100 | elapsed:    0.0s remaining:    7.6s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done: 800000/884262\n",
      "('start id: ', 800000)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of 100 | elapsed:    0.0s remaining:    6.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "submit_partial(clf, nrows, './data/sf_crime/test.csv',\n",
    "               './data/sf_crime/res.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('./data/sf_crime/test.csv')\n",
    "test_data = transform_data(test_data)\n",
    "test_data = test_data[['X', 'Y', 'Year', 'Hour', 'Friday']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proba = clf.predict_proba(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ans = []\n",
    "\n",
    "for id in xrange(len(proba)):\n",
    "    row = list(proba[id])\n",
    "    row = [id] + row\n",
    "    ans.append(row)\n",
    "\n",
    "ans = pd.DataFrame(ans)\n",
    "ans.columns = ['Id'] + list(clf.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ans.to_csv('./data/sf_crime/res.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Все что ниже - тесты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of 300 | elapsed:    0.1s remaining:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed:   17.0s finished\n",
      "[Parallel(n_jobs=4)]: Done   1 out of 300 | elapsed:    0.0s remaining:   12.5s\n",
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 2.3854960849457894)\n"
     ]
    }
   ],
   "source": [
    "# Попробуем отдельно попредсказывать для лета и зимы\n",
    "summer_data = data[(data['Month']==6) |\n",
    "                   (data['Month']==7) |\n",
    "                   (data['Month']==8)]\n",
    "y = summer_data['Category']\n",
    "X = summer_data[['X', 'Y', 'Year', 'Minutes']]\n",
    "X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=300, max_depth=14, n_jobs=4,\n",
    "                             random_state=rs, verbose=True)\n",
    "clf.fit(X_train, y_train)\n",
    "proba = clf.predict_proba(X_test)\n",
    "loss = log_loss(y_test, proba)\n",
    "print(d, loss)\n",
    "\n",
    "# 14 деревьев - оптимально\n",
    "# Для лета (month=6,7,8)     \n",
    "# n=300, max_debth=14\n",
    "# 300, 2.3849\n",
    "\n",
    "# Для зимы (month=12,1,2)\n",
    "# n=300, max_debth=14, 2.396"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of  30 | elapsed:    0.6s remaining:   19.3s\n",
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:    5.1s finished\n",
      "[Parallel(n_jobs=4)]: Done   1 out of  30 | elapsed:    0.0s remaining:    2.7s\n",
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.42175093186\n"
     ]
    }
   ],
   "source": [
    "night_data = data[data['Night'] == 0]\n",
    "y = night_data['Category']\n",
    "X = night_data[['X', 'Y', 'Month', 'Year', 'Hour']]\n",
    "X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=30, max_depth=10, n_jobs=4,\n",
    "                             random_state=rs, verbose=True)\n",
    "clf.fit(X_train, y_train)\n",
    "proba = clf.predict_proba(X_test)\n",
    "loss = log_loss(y_test, proba)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "y = data['Category']#.cat.codes\n",
    "X = data[['X', 'Y']] # 'Year',  'Minutes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\soft\\dev\\anaconda\\lib\\site-packages\\IPython\\kernel\\__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "D:\\soft\\dev\\anaconda\\lib\\site-packages\\IPython\\kernel\\__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# X['Year'] = scale(X['Year'].astype('float64'))\n",
    "# X['Minutes'] = scale(X['Minutes'].astype('float64'))\n",
    "X['X'] = scale(X['X'])\n",
    "X['Y'] = scale(X['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusters = KMeans(n_clusters=5, random_state=rs).fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 4, 4, 4])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl = map(lambda i: i == 0, clusters)\n",
    "\n",
    "y = data[cl]['Category']\n",
    "X = data[cl][['X', 'Y', 'Year', 'Minutes']]\n",
    "\n",
    "non_trea_ind = (y != 'TREA')\n",
    "y = y[non_trea_ind]\n",
    "X = X[non_trea_ind]\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of 100 | elapsed:    0.4s remaining:   52.5s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   13.4s finished\n",
      "[Parallel(n_jobs=4)]: Done   1 out of 100 | elapsed:    0.0s remaining:    8.4s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3351149024\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=14, n_jobs=4,\n",
    "                             random_state=rs, verbose=True)\n",
    "clf.fit(X_train, y_train)\n",
    "proba = clf.predict_proba(X_test)\n",
    "loss = log_loss(y_test, proba)\n",
    "\n",
    "print(loss)\n",
    "\n",
    "# 2.350\n",
    "\n",
    "# print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С кластеризацией добиться нормальных результатов пока не получилось.\n",
    "Для одних кластеров результат лучше чем в среднем по больнице, для других хуже.\n",
    "Основная проблема - из за выпадающих категорий может не работать `log_loss`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0001, 2.6700017559153704)\n",
      "Done\n",
      "(0.001, 2.6658243608443515)\n",
      "Done\n",
      "(0.01, 2.6649485640146811)\n",
      "Done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-ee73b9f89898>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\soft\\dev\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1034\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_scaling\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1036\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1037\u001b[0m                 )\n\u001b[0;32m   1038\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\soft\\dev\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.pyc\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon)\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m         epsilon)\n\u001b[0m\u001b[0;32m    841\u001b[0m     \u001b[1;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m     \u001b[1;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "days_of_week = list(data['DayOfWeek'].unique())\n",
    "y = data['Category']\n",
    "X = data[['X', 'Y', 'Year', 'Minutes'] + days_of_week]\n",
    "X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "\n",
    "# X['Year'] = scale(X['Year'].astype('float64'))\n",
    "# X['Minutes'] = scale(X['Minutes'].astype('float64'))\n",
    "# X['X'] = scale(X['X'])\n",
    "# X['Y'] = scale(X['Y'])\n",
    "\n",
    "for c in [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]:\n",
    "\n",
    "    clf = LogisticRegression(C=c)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    proba = clf.predict_proba(X_test)\n",
    "    loss = log_loss(y_test, proba)\n",
    "\n",
    "    print(c, loss)\n",
    "\n",
    "    print('Done')\n",
    "\n",
    "# 2.66622031965 # without normalization and params # normalization gives nothing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
